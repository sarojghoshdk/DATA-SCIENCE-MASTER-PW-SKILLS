{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aad4757f-3efc-4252-99c1-87f4c5cfce00",
   "metadata": {},
   "source": [
    "Question 1: What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891a1015-532a-4e38-bc94-1bbab3a052a2",
   "metadata": {},
   "source": [
    "ANSWER:-\n",
    "\n",
    "Web Scraping:- Web scraping is the process of extracting data from websites by using automated software or tools, which can access the website's HTML code, parse it, and extract the desired information. This technique can be used to collect data such as text, images, URLs, and other structured or unstructured data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c55f889-5690-48f0-a0e7-f345c157156e",
   "metadata": {},
   "source": [
    "Web scraping is used for a variety of reasons, such as:\n",
    "\n",
    "Market research: Companies can use web scraping to gather pricing information on products from competitor websites, or to collect customer reviews to improve their own products.\n",
    "\n",
    "Content aggregation: Web scraping can be used to gather news articles or blog posts from various sources and aggregate them on a single platform.\n",
    "\n",
    "Data analysis: Researchers or data scientists can use web scraping to collect data for analysis, such as social media data or information on public opinion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c9c746-8dab-4cdf-9d07-b51a2c029426",
   "metadata": {},
   "source": [
    "Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3108a2c-a99f-4685-84bb-087d27f37c47",
   "metadata": {},
   "source": [
    "ANSWER:- There are several methods used for web scraping, depending on the type of data being extracted and the structure of the website being scraped. Here are some of the most common methods:\n",
    "        \n",
    "-->> Manual scraping: This involves manually copying and pasting data from a website into a document. While this method can be effective for small amounts of data, it is time-consuming and not practical for scraping large amounts of data.  \n",
    "\n",
    "-->> Parsing HTML: This method involves parsing the HTML code of a website to extract specific data using regular expressions or other parsing techniques. It is one of the simplest methods, but it can be limited by changes to the website's HTML structure.\n",
    "\n",
    "-->> Web scraping tools: There are many web scraping tools available, such as Scrapy, Beautiful Soup, and Selenium. These tools can automate the process of scraping data from websites and provide a variety of features for parsing and extracting data.\n",
    "\n",
    "-->> APIs: Some websites provide APIs (Application Programming Interfaces) that allow developers to access and retrieve data in a structured format. This method is often faster and more reliable than traditional web scraping methods.\n",
    "\n",
    "-->> Machine Learning: Some web scraping tasks can be automated using machine learning algorithms that can \n",
    "identify patterns and extract data automatically. This method requires significant data preparation and training, but it can be more powerful and flexible than other methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd57a1e-bc1c-4fe8-b6bb-55b2bc216a77",
   "metadata": {},
   "source": [
    "Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a7c5a3-815d-426d-9c82-5a304c74d99f",
   "metadata": {},
   "source": [
    "ANSWER:- Beautiful Soup is a Python library used for web scraping purposes. It provides a simple and efficient \n",
    "     way to parse HTML and XML documents, extract data, and navigate the document tree. Beautiful Soup can \n",
    "     handle poorly formatted HTML, making it some little bit readable format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9339f7a3-0700-44f8-932a-430938ccdb8d",
   "metadata": {},
   "source": [
    "Here are some of the reasons why Beautiful Soup is widely used for web scraping:\n",
    "\n",
    "-->  Easy to learn and use: Beautiful Soup has a user-friendly syntax and a simple API that makes it easy \n",
    "     for beginners to start scraping data from websites.\n",
    "\n",
    "-->  Robust parsing capabilities: Beautiful Soup can parse even the most poorly formatted HTML, making it a \n",
    "     flexible tool for web scraping.\n",
    "\n",
    "-->  Navigation and search: Beautiful Soup provides a range of search and navigation methods to locate and \n",
    "     extract data from specific parts of an HTML document.\n",
    "\n",
    "-->  Integration with other libraries: Beautiful Soup can be integrated with other Python libraries, such as \n",
    "     requests and pandas, to handle HTTP requests and manage scraped data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff7568a-7ed4-4d4e-bc93-908829b6e2bc",
   "metadata": {},
   "source": [
    "Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812366d1-d0fd-4be4-8d92-230cb99ddba5",
   "metadata": {},
   "source": [
    "ANSWER:- Flask is a web framework that is commonly used to build web applications and APIs in Python. While it is not required for web scraping, it can be useful in certain scenarios.\n",
    "\n",
    "Here are some of the reasons why Flask is commonly used in web scraping projects:\n",
    "\n",
    "--> Easy to set up: Flask can be installed quickly and easily using pip, and requires minimal configuration to\n",
    "     get started.\n",
    "\n",
    "--> Flexible routing: Flask provides a simple and intuitive routing system that allows developers to map URLs \n",
    "     to Python functions, making it easy to build web scrapers that follow a specific pattern or logic.\n",
    "     \n",
    "--> Integration with other Python libraries: Flask integrates seamlessly with other popular Python libraries, such as Beautiful Soup, Requests, and Pandas, making it easy to build a web scraper that leverages the power of these libraries.\n",
    "\n",
    "--> Easy to deploy: Flask applications can be easily deployed to a wide range of hosting services, including Heroku,Google Cloud, and Amazon Web Services.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e08662c-cd31-4e13-8afb-bda3386f9fdb",
   "metadata": {},
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fb7e06-3677-4807-ae68-a2040abb54b4",
   "metadata": {},
   "source": [
    "ANSWER:- The AWS services used in this project are  1. AWS  Codepipeline    2. AWS Elastic Beanstalk\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee10e72-26a0-4e68-b424-4494233f5bdc",
   "metadata": {},
   "source": [
    "--> AWS CodePipeline:- AWS CodePipeline is a fully managed continuous delivery service that helps you automate your release pipelines for fast and reliable application and infrastructure updates.\n",
    "\n",
    "--> AWS Elastic Beanstalk:- Elastic Beanstalk is a service for deploying and scaling web applications and services. Upload your code and Elastic Beanstalk automatically handles the deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f98ba4e-5b69-4f51-b043-f057fbeaa6a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
